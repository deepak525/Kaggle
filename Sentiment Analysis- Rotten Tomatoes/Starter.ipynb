{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table(\"data/train.tsv\")\n",
    "test = pd.read_table(\"data/test.tsv\")\n",
    "sample = pd.read_csv(\"data/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape:  (156060, 3)\n",
      "Test Shape:  (66292, 2)\n",
      "All Data Shape: 222352 Rows, 2 Columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\", index_col = [\"PhraseId\"])\n",
    "trainlen = df.shape[0]\n",
    "test_df = pd.read_csv(\"data/test.tsv\", sep=\"\\t\", index_col = [\"PhraseId\"])\n",
    "testdex = test_df.index\n",
    "print(\"Train Shape: \",df.shape)\n",
    "print(\"Test Shape: \",test_df.shape)\n",
    "\n",
    "y = df.Sentiment.copy()\n",
    "df = pd.concat([df.drop(\"Sentiment\",axis=1),test_df], axis=0)\n",
    "print(\"All Data Shape: {} Rows, {} Columns\".format(*df.shape))\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Glimpse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115045</th>\n",
       "      <td>6128</td>\n",
       "      <td>of his narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38152</th>\n",
       "      <td>1814</td>\n",
       "      <td>Saddled with an unwieldy cast of characters an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209521</th>\n",
       "      <td>11142</td>\n",
       "      <td>that has to do with Yvan 's rambunctious , Jew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158651</th>\n",
       "      <td>8635</td>\n",
       "      <td>Guard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136219</th>\n",
       "      <td>7364</td>\n",
       "      <td>easy to be bored by as your ABC 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase\n",
       "PhraseId                                                               \n",
       "115045          6128                                   of his narrative\n",
       "38152           1814  Saddled with an unwieldy cast of characters an...\n",
       "209521         11142  that has to do with Yvan 's rambunctious , Jew...\n",
       "158651          8635                                              Guard\n",
       "136219          7364                 easy to be bored by as your ABC 's"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Representation by Sentiment Level\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    50.994489\n",
       "3    21.098936\n",
       "1    17.475971\n",
       "4     5.899013\n",
       "0     4.531590\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset Glimpse\")\n",
    "display(df.sample(5))\n",
    "print(\"Percent Representation by Sentiment Level\")\n",
    "y.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Phrase\"] = df[\"Phrase\"].astype(str) \n",
    "df[\"Phrase\"] = df[\"Phrase\"].astype(str).fillna('missing') # FILL NA\n",
    "df[\"Phrase\"] = df[\"Phrase\"].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "df[\"Phrase\" + '_num_words'] = df[\"Phrase\"].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "df[\"Phrase\" + '_num_unique_words'] = df[\"Phrase\"].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "df[\"Phrase\" + '_words_vs_unique'] = df[\"Phrase\"+'_num_unique_words'] / df[\"Phrase\"+'_num_words'] * 100 # Count Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_num_words</th>\n",
       "      <th>Phrase_num_unique_words</th>\n",
       "      <th>Phrase_words_vs_unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202743</th>\n",
       "      <td>10779</td>\n",
       "      <td>even those viewers who have little patience fo...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213493</th>\n",
       "      <td>11370</td>\n",
       "      <td>the get-go</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54538</th>\n",
       "      <td>2711</td>\n",
       "      <td>leading a double life in an american film only...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28724</th>\n",
       "      <td>1331</td>\n",
       "      <td>a semi-autobiographical film</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164680</th>\n",
       "      <td>8890</td>\n",
       "      <td>dainty psychological terror</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "202743         10779  even those viewers who have little patience fo...   \n",
       "213493         11370                                         the get-go   \n",
       "54538           2711  leading a double life in an american film only...   \n",
       "28724           1331                       a semi-autobiographical film   \n",
       "164680          8890                        dainty psychological terror   \n",
       "\n",
       "          Phrase_num_words  Phrase_num_unique_words  Phrase_words_vs_unique  \n",
       "PhraseId                                                                     \n",
       "202743                  10                       10                   100.0  \n",
       "213493                   2                        2                   100.0  \n",
       "54538                   15                       15                   100.0  \n",
       "28724                    3                        3                   100.0  \n",
       "164680                   3                        3                   100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    dtype = np.float32,\n",
    "    norm='l2',\n",
    "    min_df=0,\n",
    "    smooth_idf=False,\n",
    "    max_features=15000)\n",
    "# Fit and Transform\n",
    "word_vectorizer.fit(df.iloc[0:trainlen,:][\"Phrase\"])\n",
    "train_word_features = word_vectorizer.transform(df.iloc[0:trainlen,:][\"Phrase\"])\n",
    "test_word_features = word_vectorizer.transform(df.iloc[trainlen:,:][\"Phrase\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " SentenceId                 0\n",
      "Phrase                     0\n",
      "Phrase_num_words           0\n",
      "Phrase_num_unique_words    0\n",
      "Phrase_words_vs_unique     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill Missing Values with 0\n",
    "df.fillna(0,inplace=True)\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vars = [x for x in df.columns if x not in [\"PhraseId\",\"SentenceId\",\"Phrase\"]]\n",
    "X = hstack([csr_matrix(df.iloc[0:trainlen,:][dense_vars].values),train_word_features])\n",
    "test_df = hstack([csr_matrix(df.iloc[trainlen:,:][dense_vars].values),test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: 156060 Rows and 14991 Cols\n",
      "Test Shape: 66292 Rows and 14991 Cols\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape: {} Rows and {} Cols\".format(*X.shape))\n",
    "print(\"Test Shape: {} Rows and {} Cols\".format(*test_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "156061    3\n",
       "156062    3\n",
       "156063    2\n",
       "156064    3\n",
       "156065    2\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = clf.predict(test_df)\n",
    "submission_df = pd.Series(submission).rename(\"Sentiment\")\n",
    "submission_df.index = testdex\n",
    "submission_df.to_csv(\"MNB.csv\",index=True,header=True)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "svd.fit(X) \n",
    "\n",
    "# Transform\n",
    "X = svd.transform(X)\n",
    "test_df = svd.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0d6afecb96a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    602\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    603\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "clf.fit(X,y)\n",
    "\n",
    "# Submit\n",
    "submission = clf.predict(test_df)\n",
    "submission_df = pd.Series(submission).rename(\"Sentiment\")\n",
    "submission_df.index = testdex\n",
    "submission_df.to_csv(\"TSVD_n_MNB.csv\",index=True,header=True)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.71099325e+01,  3.81280897e+01,  4.83367161e+00,\n",
       "        -3.17664584e-02, -1.46640077e-02],\n",
       "       [ 9.42921697e+01,  9.82009357e+00, -4.54761241e-02,\n",
       "        -2.31502237e-02, -1.63010640e-02],\n",
       "       [ 9.97887078e+01, -7.08462260e+00,  1.49518002e-01,\n",
       "        -1.80322722e-02, -6.65336568e-03],\n",
       "       ...,\n",
       "       [ 9.97886988e+01, -7.08467310e+00,  1.49391503e-01,\n",
       "        -1.30846080e-02, -7.31904242e-03],\n",
       "       [ 9.96487366e+01, -8.48985978e+00,  2.25871760e-01,\n",
       "        -1.14857029e-02, -5.56379686e-03],\n",
       "       [ 9.96487366e+01, -8.48985978e+00,  2.25871760e-01,\n",
       "        -1.14857029e-02, -5.56379686e-03]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
